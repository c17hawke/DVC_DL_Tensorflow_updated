{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "none",
     "id": "b06d1227-476e-46d3-8e36-a07ef1e38294",
     "isComponent": true,
     "name": "start",
     "parents": []
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('F:/oneNeuron/PROJECT_upgrade/DVC_DL_Tensorflow_updated/research'),\n",
       " WindowsPath('/f/oneNeuron/PROJECT_upgrade/DVC_DL_Tensorflow_updated/research'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "# os.chdir(\"..\")\n",
    "# assert Path(os.getcwd())==Path(\"/f/oneNeuron/PROJECT_upgrade/DVC_DL_Tensorflow_updated\")\n",
    "\n",
    "\n",
    "Path(os.getcwd()), Path(\"/f/oneNeuron/PROJECT_upgrade/DVC_DL_Tensorflow_updated/research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "b56a9dd1-27e2-4de2-8048-16ee504ac445",
     "isComponent": true,
     "name": "import modules",
     "parents": [
      {
       "id": "b06d1227-476e-46d3-8e36-a07ef1e38294",
       "name": "start"
      }
     ]
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import urllib.request as request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "15638d01-e540-4087-a825-02e9297d89d5",
     "isComponent": true,
     "name": "logger",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging_str = \"[%(asctime)s: %(levelname)s: %(module)s]: %(message)s\"\n",
    "log_dir = \"logs\"\n",
    "log_filepath = os.path.join(log_dir, 'running_logs.log')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=logging_str,\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filepath),#, mode=\"a\"),\n",
    "        # logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logger = logging.getLogger(\"app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "ede1cc2c-b7ba-4a0b-9605-3738659f3fd9",
     "isComponent": true,
     "name": "utils",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from box.exceptions import BoxValueError\n",
    "import yaml\n",
    "import json\n",
    "import joblib\n",
    "from ensure import ensure_annotations\n",
    "from box import ConfigBox\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "@ensure_annotations\n",
    "def read_yaml(path_to_yaml: Path) -> ConfigBox:\n",
    "    \"\"\"reads yaml file and returns\n",
    "\n",
    "    Args:\n",
    "        path_to_yaml (str): path like input\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if yaml file is empty\n",
    "        e: empty file\n",
    "\n",
    "    Returns:\n",
    "        ConfigBox: ConfigBox type\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(path_to_yaml) as yaml_file:\n",
    "            content = yaml.safe_load(yaml_file)\n",
    "            logger.info(f\"yaml file: {path_to_yaml} loaded successfully\")\n",
    "            return ConfigBox(content)\n",
    "    except BoxValueError:\n",
    "        raise ValueError(\"yaml file is empty\")\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "@ensure_annotations\n",
    "def create_directories(path_to_directories: list, verbose=True):\n",
    "    \"\"\"create list of directories\n",
    "\n",
    "    Args:\n",
    "        path_to_directories (list): list of path of directories\n",
    "        ignore_log (bool, optional): ignore if multiple dirs is to be created. Defaults to False.\n",
    "    \"\"\"\n",
    "    for path in path_to_directories:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        if verbose:\n",
    "            logger.info(f\"created directory at: {path}\")\n",
    "\n",
    "@ensure_annotations\n",
    "def save_json(path: Path, data: dict):\n",
    "    \"\"\"save json data\n",
    "\n",
    "    Args:\n",
    "        path (Path): path to json file\n",
    "        data (dict): data to be saved in json file\n",
    "    \"\"\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    logger.info(f\"json file saved at: {path}\")\n",
    "\n",
    "@ensure_annotations\n",
    "def load_json(path: Path) -> ConfigBox:\n",
    "    \"\"\"load json files data\n",
    "\n",
    "    Args:\n",
    "        path (Path): path to json file\n",
    "\n",
    "    Returns:\n",
    "        ConfigBox: data as class attributes instead of dict\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        content = json.load(f)\n",
    "\n",
    "    logger.info(f\"json file loaded succesfully from: {path}\")\n",
    "    return ConfigBox(content)\n",
    "\n",
    "@ensure_annotations\n",
    "def save_bin(data: Any, path: Path):\n",
    "    \"\"\"save binary file\n",
    "\n",
    "    Args:\n",
    "        data (Any): data to be saved as binary\n",
    "        path (Path): path to binary file\n",
    "    \"\"\"\n",
    "    joblib.dump(value=data, filename=path)\n",
    "    logger.info(f\"binary file saved at: {path}\")\n",
    "\n",
    "@ensure_annotations\n",
    "def load_bin(path: Path) -> Any:\n",
    "    \"\"\"load binary data\n",
    "\n",
    "    Args:\n",
    "        path (Path): path to binary file\n",
    "\n",
    "    Returns:\n",
    "        Any: object stored in the file\n",
    "    \"\"\"\n",
    "    data = joblib.load(path)\n",
    "    logger.info(f\"binary file loaded from: {path}\")\n",
    "    return data\n",
    "\n",
    "@ensure_annotations\n",
    "def get_size(path: Path) -> str:\n",
    "    \"\"\"get size in KB\n",
    "\n",
    "    Args:\n",
    "        path (Path): path of the file\n",
    "\n",
    "    Returns:\n",
    "        str: size in KB\n",
    "    \"\"\"\n",
    "    size_in_kb = round(os.path.getsize(path)/1024)\n",
    "    return f\"~ {size_in_kb} KB\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "e02c5d03-f678-48af-9611-dd4a201ba53c",
     "isComponent": true,
     "name": "constants",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "CONFIG_FILE_PATH = Path(\"configs/config.yaml\")\n",
    "SECRETS_FILE_PATH = Path(\"configs/secrets.yaml\")\n",
    "PARAMS_FILE_PATH = Path(\"params.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "ffca97ee-c124-4a75-937d-84d4d5a259fa",
     "isComponent": true,
     "name": "entity",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## entity - \n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataIngestionConfig:\n",
    "    root_dir: Path\n",
    "    source_URL: str\n",
    "    local_data_file: Path\n",
    "    unzip_dir: Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareBaseModelConfig:\n",
    "    root_dir: Path\n",
    "    base_model_filepath: Path\n",
    "    updated_base_model_path: Path\n",
    "    param_image_size: list\n",
    "    param_classes: int\n",
    "    param_learning_rate: float\n",
    "    param_include_top: bool\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareCallbacksConfig:\n",
    "    root_dir: Path\n",
    "    tensorboard_root_log_dir: Path\n",
    "    checkpoint_model_filepath: Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentating: bool\n",
    "    params_image_size: list\n",
    "    trained_model_path: Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "13a177e6-8bee-4257-8381-b2a86f341421",
     "isComponent": true,
     "name": "configuration",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath=CONFIG_FILE_PATH, \n",
    "        params_filepath=PARAMS_FILE_PATH, \n",
    "        secrets_filepath=SECRETS_FILE_PATH):\n",
    "        self.config = read_yaml(path_to_yaml=config_filepath)\n",
    "        self.params = read_yaml(path_to_yaml=params_filepath)\n",
    "        self.secrets = read_yaml(path_to_yaml=secrets_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    def get_data_ingestion_config(self) -> DataIngestionConfig:\n",
    "        logger.info(\"getting configuration for data ingestion\")\n",
    "\n",
    "        data_ingestion = self.config.data_ingestion\n",
    "        create_directories([\n",
    "            Path(data_ingestion.root_dir)\n",
    "        ])\n",
    "        data_ingestion_config = DataIngestionConfig(\n",
    "            root_dir=Path(data_ingestion.root_dir),\n",
    "            source_URL=data_ingestion.source_URL,\n",
    "            local_data_file=Path(data_ingestion.local_data_file),\n",
    "            unzip_dir=Path(data_ingestion.unzip_dir)\n",
    "        )\n",
    "\n",
    "        return data_ingestion_config\n",
    "\n",
    "    def get_base_model_config(self) -> PrepareBaseModelConfig:\n",
    "        logger.info(\"getting configuration for base model preparation\")\n",
    "\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        create_directories([\n",
    "            Path(prepare_base_model.root_dir)\n",
    "        ])\n",
    "        prepare_base_model_config = PrepareBaseModelConfig(\n",
    "            root_dir=Path(prepare_base_model.root_dir),\n",
    "            base_model_filepath=Path(prepare_base_model.base_model_filepath),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            param_image_size=self.params.IMAGE_SIZE,\n",
    "            param_classes=self.params.CLASSES,\n",
    "            param_learning_rate=self.params.LEARNING_RATE,\n",
    "            param_include_top=self.params.INCLUDE_TOP,\n",
    "            param_weights=self.params.WEIGHTS\n",
    "        )\n",
    "        return prepare_base_model_config\n",
    "\n",
    "    def get_callbacks_config(self) -> PrepareCallbacksConfig:\n",
    "        logger.info(\"getting configuration for callbacks\")\n",
    "\n",
    "        prepare_callbacks = self.config.prepare_callbacks\n",
    "        create_directories([\n",
    "            Path(prepare_callbacks.tensorboard_root_log_dir),\n",
    "            Path(os.path.dirname(prepare_callbacks.checkpoint_model_filepath))\n",
    "        ])\n",
    "        callbacks_config = PrepareCallbacksConfig(\n",
    "            root_dir=Path(prepare_callbacks.root_dir),\n",
    "            tensorboard_root_log_dir=Path(prepare_callbacks.tensorboard_root_log_dir),\n",
    "            checkpoint_model_filepath=Path(prepare_callbacks.checkpoint_model_filepath)\n",
    "        )\n",
    "        return callbacks_config\n",
    "\n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        logger.info(\"getting configuration for model training\")\n",
    "\n",
    "        training = self.config.training\n",
    "        callbacks = self.config.prepare_callbacks\n",
    "        updated_base_model = self.config.prepare_base_model.updated_base_model_path\n",
    "        training_data = os.path.join(self.config.data_ingestion.unzip_dir, \"PetImages\")\n",
    "        params = self.params\n",
    "\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            updated_base_model_path=Path(updated_base_model),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentating=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE,\n",
    "            trained_model_path=Path(training.trained_model_path)\n",
    "        )\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "9ed679bf-2222-4af1-8515-b8477491ccd4",
     "isComponent": true,
     "name": "data ingestion",
     "parents": [
      {
       "id": "b56a9dd1-27e2-4de2-8048-16ee504ac445",
       "name": "import modules"
      }
     ]
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data already exists\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import urllib.request as request\n",
    "\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, config: DataIngestionConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def download_file(self):\n",
    "        logger.info(\"Trying to download file...\")\n",
    "        if not os.path.exists(self.config.local_data_file):\n",
    "            logger.info(\"Downloading file...\")\n",
    "            filename, headers = request.urlretrieve(\n",
    "                url=self.config.source_URL,\n",
    "                filename=self.config.local_data_file\n",
    "                )\n",
    "            logger.info(f\"{filename} downloaded! with following info: \\n{headers}\")\n",
    "        logger.info(f\"Desired file already exists of size: {get_size(self.config.local_data_file)}\")\n",
    "\n",
    "    def _get_updated_list(self, list_of_file: list) -> list:\n",
    "        return [\n",
    "            f for f in list_of_file \\\n",
    "            if f.endswith(\".jpg\") and \\\n",
    "            (\"Cat\" in f or \"Dog\" in f)\n",
    "            ]\n",
    "    \n",
    "    def _proccessing(self, zf: ZipFile, f: str, working_dir: str):\n",
    "        target_filepath = os.path.join(working_dir, f)\n",
    "        if not os.path.exists(target_filepath):\n",
    "            zf.extract(f, working_dir)\n",
    "\n",
    "        if os.path.getsize(target_filepath) == 0:\n",
    "            os.remove(target_filepath)\n",
    "            logger.info(f\"removing file: {target_filepath}\") \n",
    "\n",
    "    def unzip_and_clean(self):\n",
    "        logger.info(\"Unzipping file and checking for 0 size file...\")\n",
    "        with ZipFile(file=self.config.local_data_file, mode=\"r\") as zf:\n",
    "            list_of_file = zf.namelist()\n",
    "            updated_list_of_files = self._get_updated_list(list_of_file)\n",
    "            print(len(list_of_file), len(updated_list_of_files))\n",
    "            \n",
    "            for f in tqdm(updated_list_of_files):\n",
    "                self._proccessing(zf, f, self.config.unzip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "8936f541-186d-4e0f-93b7-3426e5321366",
     "isComponent": false,
     "name": "",
     "parents": []
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "canvas": {
   "colorPalette": [
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit"
   ],
   "parameters": [],
   "version": "1.0"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "406b130da8ef9e06d1a3a2dfd0fdafc441daca366b10d436a5c3ee2f67e0e84e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0116cf41-bcea-433d-9e28-8dee322d0dcf",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "ce8745cc-50ed-4c84-91ab-971da2d3c6de",
     "isComponent": true,
     "name": "start",
     "parents": []
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "668c3d24-4dde-4503-9004-661326ada0b1",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "89626dc9-88fc-4215-b519-79e7cb79e0c7",
     "isComponent": true,
     "name": "logger",
     "parents": []
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting logger.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile logger.py\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "\n",
    "logging_str = \"[%(asctime)s: %(levelname)s: %(module)s]: %(message)s\"\n",
    "log_dir = \"logs\"\n",
    "log_filepath = os.path.join(log_dir, 'running_logs.log')\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO, format=logging_str,\n",
    "    handlers=[\n",
    "        logging.FileHandler(log_filepath),#, mode=\"a\"),\n",
    "        # logging.StreamHandler(sys.stdout)\n",
    "    ])\n",
    "\n",
    "logger = logging.getLogger(\"app\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a594f141-def8-4a3a-bd73-43d6f00807e1",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "53680d48-9d39-4926-a5e4-9de8b0fdfc6c",
     "isComponent": true,
     "name": "utils",
     "parents": []
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting utils.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile utils.py\n",
    "\n",
    "import os\n",
    "from box.exceptions import BoxValueError\n",
    "import yaml\n",
    "import json\n",
    "import joblib\n",
    "from ensure import ensure_annotations\n",
    "from box import ConfigBox\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "from logger import logger\n",
    "\n",
    "@ensure_annotations\n",
    "def read_yaml(path_to_yaml: Path) -> ConfigBox:\n",
    "    \"\"\"reads yaml file and returns\n",
    "\n",
    "    Args:\n",
    "        path_to_yaml (str): path like input\n",
    "\n",
    "    Raises:\n",
    "        ValueError: if yaml file is empty\n",
    "        e: empty file\n",
    "\n",
    "    Returns:\n",
    "        ConfigBox: ConfigBox type\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(path_to_yaml) as yaml_file:\n",
    "            content = yaml.safe_load(yaml_file)\n",
    "            logger.info(f\"yaml file: {path_to_yaml} loaded successfully\")\n",
    "            return ConfigBox(content)\n",
    "    except BoxValueError:\n",
    "        raise ValueError(\"yaml file is empty\")\n",
    "    except Exception as e:\n",
    "        raise e\n",
    "\n",
    "@ensure_annotations\n",
    "def create_directories(path_to_directories: list, verbose=True):\n",
    "    \"\"\"create list of directories\n",
    "\n",
    "    Args:\n",
    "        path_to_directories (list): list of path of directories\n",
    "        ignore_log (bool, optional): ignore if multiple dirs is to be created. Defaults to False.\n",
    "    \"\"\"\n",
    "    for path in path_to_directories:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        if verbose:\n",
    "            logger.info(f\"created directory at: {path}\")\n",
    "\n",
    "@ensure_annotations\n",
    "def save_json(path: Path, data: dict):\n",
    "    \"\"\"save json data\n",
    "\n",
    "    Args:\n",
    "        path (Path): path to json file\n",
    "        data (dict): data to be saved in json file\n",
    "    \"\"\"\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "\n",
    "    logger.info(f\"json file saved at: {path}\")\n",
    "\n",
    "@ensure_annotations\n",
    "def load_json(path: Path) -> ConfigBox:\n",
    "    \"\"\"load json files data\n",
    "\n",
    "    Args:\n",
    "        path (Path): path to json file\n",
    "\n",
    "    Returns:\n",
    "        ConfigBox: data as class attributes instead of dict\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        content = json.load(f)\n",
    "\n",
    "    logger.info(f\"json file loaded succesfully from: {path}\")\n",
    "    return ConfigBox(content)\n",
    "\n",
    "@ensure_annotations\n",
    "def save_bin(data: Any, path: Path):\n",
    "    \"\"\"save binary file\n",
    "\n",
    "    Args:\n",
    "        data (Any): data to be saved as binary\n",
    "        path (Path): path to binary file\n",
    "    \"\"\"\n",
    "    joblib.dump(value=data, filename=path)\n",
    "    logger.info(f\"binary file saved at: {path}\")\n",
    "\n",
    "@ensure_annotations\n",
    "def load_bin(path: Path) -> Any:\n",
    "    \"\"\"load binary data\n",
    "\n",
    "    Args:\n",
    "        path (Path): path to binary file\n",
    "\n",
    "    Returns:\n",
    "        Any: object stored in the file\n",
    "    \"\"\"\n",
    "    data = joblib.load(path)\n",
    "    logger.info(f\"binary file loaded from: {path}\")\n",
    "    return data\n",
    "\n",
    "@ensure_annotations\n",
    "def get_size(path: Path) -> str:\n",
    "    \"\"\"get size in KB\n",
    "\n",
    "    Args:\n",
    "        path (Path): path of the file\n",
    "\n",
    "    Returns:\n",
    "        str: size in KB\n",
    "    \"\"\"\n",
    "    size_in_kb = round(os.path.getsize(path)/1024)\n",
    "    return f\"~ {size_in_kb} KB\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c84f0847-51ad-45b0-821f-b60b1d3c74c0",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "3b18eb1d-cce5-4a51-97da-411ff03f1646",
     "isComponent": true,
     "name": "data ingestion",
     "parents": [
      {
       "id": "ce8745cc-50ed-4c84-91ab-971da2d3c6de",
       "name": "start"
      }
     ]
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25006 25000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25000/25000 [00:28<00:00, 883.08it/s]\n"
     ]
    }
   ],
   "source": [
    "## Configs\n",
    "from utils import create_directories\n",
    "\n",
    "local_data_file = Path(\"artifacts/data_ingestion/data.zip\")\n",
    "source_URL = \"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\"\n",
    "unzip_dir, zipfile_name = os.path.split(local_data_file)\n",
    "create_directories([Path(unzip_dir)])\n",
    "\n",
    "from zipfile import ZipFile\n",
    "import urllib.request as request\n",
    "from logger import logger\n",
    "from utils import get_size\n",
    "from tqdm import tqdm\n",
    "\n",
    "try:\n",
    "    logger.info(\"Trying to download file...\")\n",
    "    if not os.path.exists(local_data_file):\n",
    "        logger.info(\"Downloading file...\")\n",
    "        filename, headers = request.urlretrieve(\n",
    "            url=source_URL,\n",
    "            filename=local_data_file\n",
    "            )\n",
    "        logger.info(f\"{filename} downloaded! with following info: \\n{headers}\")\n",
    "    logger.info(f\"Desired file already exists of size: {get_size(local_data_file)}\")\n",
    "except Exception as e:\n",
    "    raise e\n",
    "\n",
    "def _get_updated_list(list_of_file: list) -> list:\n",
    "    return [\n",
    "        f for f in list_of_file \\\n",
    "        if f.endswith(\".jpg\") and \\\n",
    "        (\"Cat\" in f or \"Dog\" in f)\n",
    "        ]\n",
    "\n",
    "def _proccessing(zf: ZipFile, f: str, working_dir: str):\n",
    "    target_filepath = os.path.join(working_dir, f)\n",
    "    if not os.path.exists(target_filepath):\n",
    "        zf.extract(f, working_dir)\n",
    "\n",
    "    if os.path.getsize(target_filepath) == 0:\n",
    "        os.remove(target_filepath)\n",
    "        logger.info(f\"removing file: {target_filepath}\") \n",
    "\n",
    "\n",
    "logger.info(\"Unzipping file and checking for 0 size file...\")\n",
    "with ZipFile(file=local_data_file, mode=\"r\") as zf:\n",
    "    list_of_file = zf.namelist()\n",
    "    updated_list_of_files = _get_updated_list(list_of_file)\n",
    "    print(len(list_of_file), len(updated_list_of_files))\n",
    "\n",
    "    for f in tqdm(updated_list_of_files):\n",
    "        _proccessing(zf, f, unzip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ca42aa-e038-4a7e-925b-6102ded67d5a",
   "metadata": {
    "canvas": {
     "comments": [],
     "componentType": "CodeCell",
     "copiedOriginId": null,
     "diskcache": false,
     "headerColor": "inherit",
     "id": "0b576bc8-3a1d-463e-b7ee-9f937bfdfc8f",
     "isComponent": true,
     "name": "prepare base model",
     "parents": [
      {
       "id": "3b18eb1d-cce5-4a51-97da-411ff03f1646",
       "name": "data ingestion"
      }
     ]
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "base_model_filepath = \n",
    "updated_base_model_path = \n",
    "param_image_size\n",
    "param_classes\n",
    "param_learning_rate\n",
    "param_include_top\n",
    "param_weights\n",
    "\n",
    "from utils import create_directories\n",
    "from logger import logger\n",
    "import io\n",
    "\n",
    "def save_model(path: Path, model: tf.keras.Model):\n",
    "    model.save(path)\n",
    "    logger.info(f\"model saved at: {path}\")\n",
    "\n",
    "def get_base_model(model_name: str=\"VGG16\"):\n",
    "    logger.info(f\"creating base model for transfer learning...\")\n",
    "    self.model = tf.keras.applications.vgg16.VGG16(\n",
    "        input_shape=self.config.param_image_size,\n",
    "        weights=self.config.param_weights,\n",
    "        include_top=self.config.param_include_top\n",
    "    )\n",
    "    model_path = self.config.base_model_filepath\n",
    "\n",
    "    self.save_model(path=model_path, model=self.model)\n",
    "    logger.info(f\"base model: {model_name} saved!\")\n",
    "\n",
    "\n",
    "@staticmethod\n",
    "def _prepare_full_model(model, classes, freeze_all, freeze_till, learning_rate):\n",
    "    if freeze_all:\n",
    "        logger.info(\"freeze all the layers of base CNN layer\")\n",
    "        for layer in model.layers:\n",
    "            layer.trainable = False\n",
    "    elif (freeze_till is not None) and (freeze_till > 0):\n",
    "        logger.info(f\"freeze the layers of base CNN layer till {freeze_till}\")\n",
    "        for layer in model.layers[:-freeze_till]:\n",
    "            layer.trainable = False\n",
    "\n",
    "    ## add our fully connected layers\n",
    "    flatten_in = tf.keras.layers.Flatten()(model.output)\n",
    "    prediction = tf.keras.layers.Dense(\n",
    "        units=classes,\n",
    "        activation=\"softmax\"\n",
    "    )(flatten_in)\n",
    "\n",
    "    full_model = tf.keras.models.Model(\n",
    "        inputs = model.input,\n",
    "        outputs = prediction\n",
    "    )\n",
    "\n",
    "    full_model.compile(\n",
    "        optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "        loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "        metrics = [\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    logger.info(\"custom model is compiled and ready to be trained\")\n",
    "    full_model.summary()\n",
    "    return full_model\n",
    "\n",
    "@staticmethod\n",
    "def _log_model_summary(full_model):\n",
    "    with io.StringIO() as stream:\n",
    "        full_model.summary(print_fn=lambda x: stream.write(f\"{x}\\n\"))\n",
    "        summary_str = stream.getvalue()\n",
    "    return summary_str\n",
    "\n",
    "def update_base_model(self):\n",
    "    logger.info(f\"creating custom model for transfer learning\")\n",
    "    self.full_model = self._prepare_full_model(\n",
    "        model=self.model,\n",
    "        classes=self.config.param_classes,\n",
    "        freeze_all=True,\n",
    "        freeze_till=None,\n",
    "        learning_rate=self.config.param_learning_rate\n",
    "    )\n",
    "\n",
    "\n",
    "    logger.info(f\"full model summary: \\n{self._log_model_summary(self.full_model)}\")\n",
    "\n",
    "    self.save_model(path=self.config.updated_base_model_path, model=self.full_model)\n",
    "    logger.info(f\"custom model saved!\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "canvas": {
   "colorPalette": [
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit",
    "inherit"
   ],
   "parameters": [],
   "version": "1.0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "406b130da8ef9e06d1a3a2dfd0fdafc441daca366b10d436a5c3ee2f67e0e84e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
